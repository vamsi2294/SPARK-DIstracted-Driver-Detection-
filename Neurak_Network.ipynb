{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X, y = sklearn.datasets.make_moons(200, noise=0.20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.43, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_layer=3000\n",
    "output_layer=10\n",
    "nn_input_dim = 2 # input layer dimensionality\n",
    "nn_output_dim = 2 # output layer dimensionality\n",
    "\n",
    "#gradient decent\n",
    "eta=0.01\n",
    "reg_lambda=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_weights(nn_input_dim, nn_hdim,nn_output_dim):\n",
    "    # Initialize the parameters to random values. We need to learn these.\n",
    "    np.random.seed(0)\n",
    "    W1 = np.random.randn(nn_input_dim, nn_hdim) / np.sqrt(nn_input_dim)\n",
    "    b1 = np.zeros((1, nn_hdim))\n",
    "    W2 = np.random.randn(nn_hdim, nn_output_dim) / np.sqrt(nn_hdim)\n",
    "    b2 = np.zeros((1, nn_output_dim))\n",
    "    return W1,b1,W2,b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    exp_scores = np.exp(z)\n",
    "    return (exp_scores / np.sum(exp_scores, axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feedforward(W1,b1,W2,b2,X):\n",
    "    for i in X:\n",
    "    # Forward propagation\n",
    "        z1 = X.dot(W1) + b1\n",
    "        #print(z1)\n",
    "        a1 = np.tanh(z1)\n",
    "        z2 = a1.dot(W2) + b2\n",
    "        exp_scores = np.exp(z2)\n",
    "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "    #print(probs)\n",
    "    return z1,a1,z2,probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feedforward(W1,b1,W2,b2,X):\n",
    "    # Forward propagation\n",
    "    z1 = X.dot(W1) + b1\n",
    "        #print(z1)\n",
    "    a1 = np.tanh(z1)\n",
    "    z2 = a1.dot(W2) + b2\n",
    "    exp_scores = np.exp(z2)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "    #print(probs)\n",
    "    return z1,a1,z2,probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function learns parameters for the neural network and returns the model.\n",
    "# - nn_hdim: Number of nodes in the hidden layer\n",
    "# - num_passes: Number of passes through the training data for gradient descent\n",
    "# - print_loss: If True, print the loss every 1000 iterations\n",
    "def build_model(X,y,nn_hdim, num_passes, print_loss):\n",
    "    # This is what we return at the end\n",
    "    model = {}\n",
    "    W1,b1,W2,b2=initialize_weights(nn_input_dim, nn_hdim,nn_output_dim)\n",
    "    # Gradient descent. For each batch...\n",
    "    for i in range(0,num_passes):\n",
    "        #Forward propagation       \n",
    "        z1,a1,z2,probs=feedforward(W1,b1,W2,b2,X)\n",
    "        # Backpropagation\n",
    "        delta3 = probs\n",
    "        delta3[range(len(X)), y] -= 1\n",
    "        dW2 = (a1.T).dot(delta3)\n",
    "        db2 = np.sum(delta3, axis=0, keepdims=True)\n",
    "        delta2 = delta3.dot(W2.T) * (1 - np.power(a1, 2))\n",
    "        dW1 = np.dot(X.T, delta2)\n",
    "        db1 = np.sum(delta2, axis=0)\n",
    "\n",
    "        # Add regularization terms (b1 and b2 don't have regularization terms)\n",
    "        dW2 += reg_lambda * W2\n",
    "        dW1 += reg_lambda * W1\n",
    "\n",
    "        # Gradient descent parameter update\n",
    "        W1 += -eta * dW1\n",
    "        b1 += -eta * db1\n",
    "        W2 += -eta * dW2\n",
    "        b2 += -eta * db2\n",
    "        \n",
    "        # Assign new parameters to the model\n",
    "        model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
    "        \n",
    "        # Optionally print the loss.\n",
    "        # This is expensive because it uses the whole dataset, so we don't want to do it too often.\n",
    "        if print_loss and i % 1000 == 0:\n",
    "          print(\"Loss after iteration %i: %f\" %(i, calculate_loss(model,X,y)))  \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_loss(model,X,y):\n",
    "    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n",
    "    z1,a1,z2,probs=feedforward(W1,b1,W2,b2,X)\n",
    "    # Calculating the loss\n",
    "    corect_logprobs = -np.log(probs[range(num_examples), y])\n",
    "    data_loss = np.sum(corect_logprobs)\n",
    "    # Add regulatization term to loss (optional)\n",
    "    data_loss += reg_lambda/2 * (np.sum(np.square(W1)) + np.sum(np.square(W2)))\n",
    "    return 1./num_examples * data_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper function to predict an output (0 or 1)\n",
    "def predict(model, x):\n",
    "    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n",
    "    # Forward propagation\n",
    "    z1,a1,z2,probs=feedforward(W1,b1,W2,b2,x)\n",
    "    return np.argmax(probs,axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build a model with a 3-dimensional hidden layer\n",
    "num_examples = len(X_train)\n",
    "model = build_model(X_train,y_train,4,2000, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-266-4cbd46abfb26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdelta3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdelta3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "delta3=predict(model,X_train)\n",
    "delta3[range(num_examples), y_train] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03173218, -0.03173218],\n",
       "       [ 0.1496922 , -0.1496922 ],\n",
       "       [-0.07882916,  0.07882916],\n",
       "       [-0.08546984,  0.08546984],\n",
       "       [-0.09370515,  0.09370515],\n",
       "       [ 0.85938742, -0.85938742],\n",
       "       [ 0.24848691, -0.24848691],\n",
       "       [ 0.67472456, -0.67472456],\n",
       "       [ 0.09119246, -0.09119246],\n",
       "       [ 0.67981446, -0.67981446],\n",
       "       [-0.19028324,  0.19028324],\n",
       "       [-0.59661492,  0.59661492],\n",
       "       [ 0.07652409, -0.07652409],\n",
       "       [-0.20781237,  0.20781237],\n",
       "       [ 0.05173825, -0.05173825],\n",
       "       [ 0.04472622, -0.04472622],\n",
       "       [-0.09026164,  0.09026164],\n",
       "       [-0.79645322,  0.79645322],\n",
       "       [-0.13341202,  0.13341202],\n",
       "       [-0.04919831,  0.04919831],\n",
       "       [-0.10599154,  0.10599154],\n",
       "       [ 0.04227617, -0.04227617],\n",
       "       [-0.03378793,  0.03378793],\n",
       "       [ 0.55244027, -0.55244027],\n",
       "       [-0.11341456,  0.11341456],\n",
       "       [-0.43359977,  0.43359977],\n",
       "       [-0.08041381,  0.08041381],\n",
       "       [-0.12226897,  0.12226897],\n",
       "       [ 0.03229087, -0.03229087],\n",
       "       [-0.07331691,  0.07331691],\n",
       "       [ 0.04073979, -0.04073979],\n",
       "       [ 0.04297205, -0.04297205],\n",
       "       [ 0.05759771, -0.05759771],\n",
       "       [ 0.44182183, -0.44182183],\n",
       "       [ 0.03036541, -0.03036541],\n",
       "       [ 0.04402135, -0.04402135],\n",
       "       [-0.04759131,  0.04759131],\n",
       "       [ 0.03449346, -0.03449346],\n",
       "       [ 0.4594193 , -0.4594193 ],\n",
       "       [ 0.07460036, -0.07460036],\n",
       "       [ 0.21020844, -0.21020844],\n",
       "       [ 0.03228216, -0.03228216],\n",
       "       [-0.04332679,  0.04332679],\n",
       "       [ 0.8626228 , -0.8626228 ],\n",
       "       [ 0.03718256, -0.03718256],\n",
       "       [-0.07018015,  0.07018015],\n",
       "       [ 0.12650494, -0.12650494],\n",
       "       [ 0.05175549, -0.05175549],\n",
       "       [ 0.23913545, -0.23913545],\n",
       "       [ 0.24740485, -0.24740485],\n",
       "       [-0.56017874,  0.56017874],\n",
       "       [ 0.8229841 , -0.8229841 ],\n",
       "       [-0.3112845 ,  0.3112845 ],\n",
       "       [ 0.08579808, -0.08579808],\n",
       "       [ 0.04324962, -0.04324962],\n",
       "       [-0.08835962,  0.08835962],\n",
       "       [-0.08367881,  0.08367881],\n",
       "       [ 0.03957095, -0.03957095],\n",
       "       [ 0.09051856, -0.09051856],\n",
       "       [-0.21217898,  0.21217898],\n",
       "       [ 0.03431335, -0.03431335],\n",
       "       [-0.04856085,  0.04856085],\n",
       "       [-0.54624841,  0.54624841],\n",
       "       [ 0.37456277, -0.37456277],\n",
       "       [ 0.58927776, -0.58927776],\n",
       "       [-0.07934364,  0.07934364],\n",
       "       [ 0.13930568, -0.13930568],\n",
       "       [-0.5761193 ,  0.5761193 ],\n",
       "       [ 0.06457664, -0.06457664],\n",
       "       [-0.0451741 ,  0.0451741 ],\n",
       "       [-0.13654909,  0.13654909],\n",
       "       [-0.08229573,  0.08229573],\n",
       "       [ 0.10514753, -0.10514753],\n",
       "       [ 0.04350648, -0.04350648],\n",
       "       [ 0.05186711, -0.05186711],\n",
       "       [ 0.06276578, -0.06276578],\n",
       "       [ 0.06636721, -0.06636721],\n",
       "       [ 0.04035912, -0.04035912],\n",
       "       [-0.56365487,  0.56365487],\n",
       "       [ 0.03291098, -0.03291098],\n",
       "       [-0.02879461,  0.02879461],\n",
       "       [-0.03690652,  0.03690652],\n",
       "       [ 0.12618072, -0.12618072],\n",
       "       [-0.08325765,  0.08325765],\n",
       "       [ 0.08427372, -0.08427372],\n",
       "       [ 0.04799361, -0.04799361],\n",
       "       [ 0.03739324, -0.03739324],\n",
       "       [ 0.0287102 , -0.0287102 ],\n",
       "       [ 0.1956273 , -0.1956273 ],\n",
       "       [-0.65880312,  0.65880312],\n",
       "       [ 0.3777825 , -0.3777825 ],\n",
       "       [-0.86079388,  0.86079388],\n",
       "       [ 0.34671602, -0.34671602],\n",
       "       [-0.70833194,  0.70833194],\n",
       "       [ 0.02986422, -0.02986422],\n",
       "       [ 0.07500874, -0.07500874],\n",
       "       [ 0.32432169, -0.32432169],\n",
       "       [-0.47125911,  0.47125911],\n",
       "       [ 0.028199  , -0.028199  ],\n",
       "       [-0.91606595,  0.91606595],\n",
       "       [ 0.23860511, -0.23860511],\n",
       "       [-0.15980983,  0.15980983],\n",
       "       [-0.03772444,  0.03772444],\n",
       "       [ 0.06040909, -0.06040909],\n",
       "       [-0.11414635,  0.11414635],\n",
       "       [ 0.06806303, -0.06806303],\n",
       "       [ 0.07613838, -0.07613838],\n",
       "       [-0.08837505,  0.08837505],\n",
       "       [-0.04198075,  0.04198075],\n",
       "       [-0.2105643 ,  0.2105643 ],\n",
       "       [-0.03777009,  0.03777009],\n",
       "       [ 0.0809912 , -0.0809912 ],\n",
       "       [-0.13879923,  0.13879923],\n",
       "       [-0.0533207 ,  0.0533207 ]])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict(model,X_test[0])\n",
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array 1 cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-276-63fb0c891d07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\vamsi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\vamsi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\vamsi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \"\"\"\n\u001b[1;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\vamsi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \"\"\"\n\u001b[1;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\vamsi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[0;32m--> 126\u001b[0;31m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Singleton array 1 cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test[0], y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function learns parameters for the neural network and returns the model.\n",
    "# - nn_hdim: Number of nodes in the hidden layer\n",
    "# - num_passes: Number of passes through the training data for gradient descent\n",
    "# - print_loss: If True, print the loss every 1000 iterations\n",
    "def build_model(X,y,nn_hdim, num_passes, print_loss):\n",
    "    # This is what we return at the end\n",
    "    model = {}\n",
    "    W1,b1,W2,b2=initialize_weights(nn_input_dim, nn_hdim,nn_output_dim)\n",
    "    # Gradient descent. For each batch...\n",
    "    for i in range(0,num_passes):\n",
    "        #Forward propagation       \n",
    "        z1,a1,z2,probs=feedforward(W1,b1,W2,b2,X)\n",
    "        # Backpropagation\n",
    "        delta3 = probs\n",
    "        delta3[range(len(X)), y] -= 1\n",
    "        dW2 = (a1.T).dot(delta3)\n",
    "        db2 = np.sum(delta3, axis=0, keepdims=True)\n",
    "        delta2 = delta3.dot(W2.T) * (1 - np.power(a1, 2))\n",
    "        dW1 = np.dot(X.T, delta2)\n",
    "        db1 = np.sum(delta2, axis=0)\n",
    "\n",
    "        # Add regularization terms (b1 and b2 don't have regularization terms)\n",
    "        dW2 += reg_lambda * W2\n",
    "        dW1 += reg_lambda * W1\n",
    "\n",
    "        # Gradient descent parameter update\n",
    "        W1 += -eta * dW1\n",
    "        b1 += -eta * db1\n",
    "        W2 += -eta * dW2\n",
    "        b2 += -eta * db2\n",
    "        \n",
    "        # Assign new parameters to the model\n",
    "        model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
    "        \n",
    "        # Optionally print the loss.\n",
    "        # This is expensive because it uses the whole dataset, so we don't want to do it too often.\n",
    "        if print_loss and i % 1000 == 0:\n",
    "          print(\"Loss after iteration %i: %f\" %(i, calculate_loss(model,X,y)))  \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_examples = len(X_train[0])\n",
    "for i in X_train:\n",
    "    model = build_model(X_train,y_train,4,2000, False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
